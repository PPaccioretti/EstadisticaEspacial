{
  "hash": "e38194bb417021347287ffe9137ec4cb",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: \"Pablo Paccioretti\"\nformat: \n  revealjs:\n    #transition: fade\n    theme: styles/theme_slides.scss\nslide-number: \"c/t\"\nchalkboard:\n    theme: chalkboard\n    chalk-effect: 0\nfootnotes-hover: true\nmultiplex: true\nfooter: \"\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Estimación frecuentista y bayesiana de modelos lineales para datos con correlación espacial\n\nMónica Balzarini, Pablo Paccioretti\n\nOctubre, 2023\n\n<!-- ## Análisis de datos. Paradigmas -->\n\n<!-- ::: columns -->\n<!-- ::: {.column width=\"47%\"} -->\n<!-- ### Analítico -->\n\n<!-- -   Fundamentación matemática de los procedimientos estadísticos -->\n<!-- -   Resultados muchas veces exactos -->\n<!-- -   Expresiones cerradas para medidas de incertidumbre, al menos -->\n<!--     asintóticas -->\n<!-- -   Teoremas de respaldo, necesidad de supuestos distribucionales -->\n<!-- -   Modelos estadísticos -->\n<!-- -   -->\n\n<!-- ::: {.column width=\"6%\"} -->\n<!-- ::: Clasificación y Predicción -->\n<!-- ::: -->\n\n<!-- ::: {.column width=\"47%\"} -->\n<!-- ### Computación intensiva -->\n\n<!-- -   Soluciones númericas -->\n<!-- -   Resultados aproximados por procesos iterativos -->\n<!-- -   Capacidad de modelar situaciones más complejas con supuestos menos -->\n<!--     restrictivos -->\n<!-- -   Aprendizajes automáticos -->\n<!-- -   Más exploratorios que inferenciales -->\n<!-- -   Modelos o algoritmos explicativos -->\n<!-- -   Clasificación y Predicción -->\n<!-- ::: -->\n<!-- ::: -->\n\n## Modelo Lineal General\n\n$$Y = Valor\\ Esperado + Error$$\n\n$$Y = Modelo\\ de\\ Media + Modelo\\ de\\ Varianza\\ y \\ Covarianza$$\n\nEn el Modelo de Media, la respuesta se relaciona linealmente con\nregresoras y/o variables de clasificación (Modelos de Regresión, Modelos\nde ANAVA)\n\nEl Modelo de varianzas y covarianzas se determina con supuestos\ndistribucionales para los términos de error:\n\n::: columns\n::: {.column width=\"30%\"}\n-   i.i.d Normales\n-   no correlacionados\n-   varianza constante\n:::\n\n::: {.column width=\"70%\"}\n::: {.fragment .fade-in-then-out}\n::: {.callout-note appearance=\"simple\"}\nHay alternativas para corregir la falta de cumplimiento de algunos de\nestos supuestos.\n:::\n\n::: {.callout-caution appearance=\"simple\"}\nEl cumplimiento de los supuestos no son necesarios para la estimación\npero sí para la inferencia, esto significa que el valor-p puede no ser\nreal en caso de incumplimiento de estos.\n:::\n:::\n:::\n:::\n\n## Modelo de Regresión Lineal\n\n$$Y_{ij} = \\beta_0 + \\beta_1 x_{ij}+\\varepsilon_{ij}$$\n\n$$\\varepsilon_{ij} \\sim N \\big(0, \\sigma^2 \\big) \\: \\: \\:\ncov(\\varepsilon_{ij}, \\varepsilon_{i^{\\prime} j^{\\prime}}) = 0 \\: \\forall ij \\neq i^{\\prime} j^{\\prime}$$\n\nDonde:\n\n-   $Y_{ij}$ es la observación en la $j-ésima$ repetición de la $i-ésima$\n    variable explicativa.\n-   $\\beta_0$ es un término constante o intercepto\n-   $\\beta_1$ es el efecto de la variable explicativa\n-   $x_{ij}$ es el valor de la $j-ésima$ repetición de la $i-ésima$\n    variable explicativa.\n-   $\\varepsilon_{ij}$ es un efecto aleatorio o término de error asociado a la\nobservación $Y_{ij}$\n\n::: {.callout-note appearance=\"simple\"}\n\nAlternativamente la covarianza entre los términos de error puede ser\ndistinta de cero, por ejemplo covarianza positiva expresada como función\nde la distancia entre observaciones\n\n:::\n\n# Modelo Lineal Mixto {background-color=\"#546e7a\"}\n\n## Modelo Lineal Mixto\n\n### Permite estimar un modelo para respuestas normales sin que se cumpla el supuesto de independencia y/o de homogeneidad de varianzas\n\nLa respuesta se modela como función de variables explicativas de efectos \nfijos y de efectos aleatorios.\n\nLa correlación se puede abordar de dos formas:\n\n1. Especificando correlaciones entre los términos de error\n2. Incorporando efectos aleatorios que inducen correlaciones entre los \ndatos que comparten el mismo nivel del efecto\n\n::: {.callout-note appearance=\"simple\"}\n\nLa correlación entre los errores se especifica como función de la distancia \nespacial entre las observaciones (por ej. correlación espacial exponencial o \nesférica como modelos para la caída de las correlaciones a medida que aumenta \nla distancia entre observaciones)\n\n:::\n\n\n------------------------------------------------------------------------\n\n## Modelo Lineal Mixto. Efectos Fijos vs. Aleatorios\n\n-   Niveles arbitrariamente determinados vs. muestra aleatoria de\n    niveles (asociado a una distribución de probabilidad)\n-   Mecanismos de colección\n-   Espacio de inferencia\n-   Estrategia de modelación\n-   Cantidad de niveles\n-   Calidad de la estimación de componentes de varianza\n-   Cómputo de covarianzas\n\n\n## Modelo Lineal Mixto = Modelo Jerárquico Normal\n\nUn modelo jerárquico es un modelo especificado en etapas.\n\n*Ejemplo*: Modelo lineal mixto con efectos aleatorios $u$.\n\n$$y \\vert \\beta, u, \\sigma^2 \\sim N(x^{\\prime} \\beta + z^{\\prime}u, \\sigma^2I) \\\\\nu \\sim N(0, D(\\theta))$$\n\n\n\n# Modelo Lineal Generalizado {background-color=\"#546e7a\"}\n\n\n## Modelo Lineal Generalizado. Componentes\n\n1.  Distribución de las observaciones\n    -   No necesariamente normal, no asume homogeneidad de varianzas\n2.  Predictor lineal\n    -   Combinación lineal del efecto de las fuentes de variación más un\n        intercepto\n3.  Función de enlace\n    -   Permite ajustar un modelo lineal a la media de la respuesta.\n        Cuando estimamos los parámetros del modelo lineal, lo hacemos en\n        la escala de la función de enlace. Su inversa nos da el valor\n        predicho en la escala de las observaciones\n\n## Modelo Lineal Generalizado\n\n-   Lineal\n    -   Una transformación de la media (valor esperado de la respuesta)\n        se relaciona linealmente con las fuentes de variación\n        reconocidas a priori\n    -   Predictor lineal de una función de la esperanza o media de $Y$,\n        $E(Y)$\n-   Generalizado\n    -   La componente aleatoria puede ser no-normal (distribución\n        miembro de la familia exponencial como es el caso de Bernouille,\n        Binomial y Poisson para modelar presencia/ausencia, proporciones\n        y conteos respectivamente y el caso de distribuciones continuas:\n        Normal, Gamma, Inversa Gaussiana)\n\n# Modelo Lineal Generalizado Mixto {background-color=\"#546e7a\"}\n\n## Modelo Lineal Generalizado Mixto (GLMM)\n\nNo necesariamente normal, no-homogeneidad y no independencia\n\nMLGM permite trabajar datos no normales (por ejemplo variables binarias\ny conteos) y correlaciones, a través de la incorporación de efectos\naleatorios. Es un modelo Jerárquico\n\n\n# Paradigmas de estimación/predicción {background-color=\"#546e7a\"}\n\n\n---\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Frecuentista**\n\nRelacionan la variable respuesta con variables explicativas a través de\nparámetros desconocidos. Los parámetros son constantes que se estiman\ncon determinada confianza.\n\n:::\n\n::: {.column width=\"50%\"}\n\n**Bayesiano**\n\nRelacionan la variable dependiente con variables explicativas a través\nde parámetros desconocidos. Los parámetros se interpretan en término de\nprobabilidades bayesianas; se supone una distribución \"a priori\" para\ncada parámetro y se deriva la distribución \"a posteriori\" de cada\nparámetro y para la predicción de Y.\n\n:::\n\n::::\n\n# Modelos Mixtos (o Multinivel): estimación frecuentista {background-color=\"#546e7a\"}\n\n\n## Modelo Jerárquico Normal\n\nSe utiliza Máxima Verosimilitud (ML) o Máxima Verosimilitud Restringida (REML).\n\nSe estiman los parámetros de la estructura de media (coeficientes de regresión)\ny los parámetros de varianza y covarianza asociados a los términos de error \n(varianza nugget, varianza del proceso con datos independientes y rango). \n\n::: {.callout-note appearance=\"simple\"}\n\nLos errores estándares se ajustan por correlación espacial.\n\n:::\n\n::: {.callout-warning appearance=\"simple\"}\n\nCon muchos datos, la computación de distancias y de la verosimilitud es \ncostosa. Se deben usar otros métodos de estimación.\n\n:::\n\n## Modelo Jerárquico Bayesiano\n\n-   Los parámetros se interpretan en término de probabilidades\n    bayesianas; se supone una distribución \"a priori\" para cada\n    parámetro y se deriva la distribución \"a posteriori\" de cada\n    parámetro.\n-   La media, moda o mediana de la distribución a posteriori se usa como\n    proxy del parámetro.\n-   Las \"a priori\" son parte del modelo y una manera de expresar la\n    distribución de probabilidad de los datos dados los parámetros.\n-   Los parámetros de las distribuciones \"a priori\" se llaman\n    hiperparámetros.\n-   \"a posteriori\" = actualización de la \"a priori\" con los datos\n    observados.\n-   Permite otorgar grado de creencia (intervalo de credibilidad)\n\n## Pensando en términos de Intervalos de credibilidad\n\n-   La información previa sobre los parámetros se resumen en\n    distribuciones de probabilidad (distribuciones a priori) a partir de\n    las cuales se estima la distribución de probabilidad a posteriori\n    dadas las observaciones.\n\n-   La estimaciones puntuales de los parámetros de interés se obtienen\n    calculando medidas resumen de la distribución a posteriori.\n\n-   Se informan intervalos de credibilidad calculados desde percentiles\n    de la distribución a posteriori.\n\n-   La credibilidad se interpreta como la probabilidad de que el valor\n    estimado para el parámetro pertenezca al intervalo reportado, dado\n    los datos observados\n\n## ¿Por qué Jerárquico?\n\nLos datos $Z$ tienen una distribución condicional dado el proceso\nlatente que los ha generado $Y$, que a su vez tiene una distribución\ncondicional a ciertos parámetros $\\theta$ y $\\theta$ tiene a su vez una\ndistribución \"a priori\".\n\n\n\n+:---------------------------+:----------------------------------------+\n| Modelo para los datos      | $\\left[ Z \\big\\vert Y, \\theta \\right]$  |\n|                            |                                         |\n| Modelo para el proceso     | $\\left[ Y \\big\\vert \\theta \\right]$     |\n|                            |                                         |\n| Modelo para los parámetros | $\\left[ \\theta \\right]$                 |\n+----------------------------+-----------------------------------------+\n\n\n\n\n## Modelo Jerárquico Bayesiano\n\n\nEn un modelo bayesiano, los parámetros se consideran variables\naleatorias y tienen distribuciones a priori. Continuando con el ejemplo\nanterior:\n\n$$\\beta \\sim \\pi (\\beta)$$\n\nEn el modelo jerárquico bayesiano, los parámetros de las distribuciones\na priori de los parámetros (llamados *hiperparámetros*) también se\nconsideran variables aleatorias, y también tienen ditribuciones a\npriori.\n\n$$\\sigma^2 \\sim \\pi (\\sigma^2)$$\n\n## Modelo Gausiano Latente (una clase de MJB)\n\nEl predictor lineal contiene el intercepto, los efectos de las\ncovariables y funciones desconocidas $f^{(k)}$ que incluyen los efectos\naleatorios:\n\n$$\\eta_i = \\mu + \\sum_{j}{\\beta_j z_{ij}} + \\sum_{k}{f^{(k)}u_{ik}}$$\n\nLos componentes del predictor lineal forman un campo latente\n$x=(\\eta, \\mu, \\beta, f)$. Además de los parámetros de la verosimilitud,\ntambién habrá hiperparámetros $\\theta$. En un MLG, todos los componentes\ndel predictor lineal deben tener distribuciones a priori gausianas, pero\n$\\theta$ puede tener distribuciones a priori no gausianas.\n\nEl MLG se puede escribir formalmente como:\n\n$$y \\vert x, \\theta \\sim \\prod \\pi (y_i \\vert \\eta_i, \\theta) \\\\\nx \\vert \\theta \\sim N(0, Q^{-1}(\\theta)) \\\\\n\\theta \\sim \\pi(\\theta)$$\n\n## ¿Por qué INLA?\n\nLas distribuciones a posteriori de los modelos bayesianos no suelen\nestar disponibles analíticamente y usualmente se encuentran con métodos\nde simulación por cadenas de Markov Monte Carlo (MCMC) (Besag et al.,\n1995). Estos métodos han permitido resolver modelos complejos sin la\nnecesidad de imponer estructuras que lo simplifiquen. Pero, el método\nMCMC conlleva alta demanda computacional. Rue et al (2009) propusieron\nuna alternativa para aproximar la distribución a posteriori en contextos\nde datos espaciales. La simplificación se produce por el supuesto de\nexistencia de un campo aleatorio gaussiano markoviano (las correlaciones\nespaciales sólo dependen de los sitios en el vecindario).\n\nINLA (*Integrated Nested Laplace Approximations*; Rue, Martino y Chopin,\n2009) es un método que permite estimar la distribución marginal a\nposteriori de los parámetros. INLA permite la inferencia bayesiana de los\nModelos Gaussianos Latentes.\n\n--------------------------------------------------------------------------------\n\n## Estimación vía INLA\n\nINLA es más rápido que MCMC porque el campo latente al que referencia es\nun campo aleatorio gaussiano de Markov (GMRF) y por tanto tiene matriz\nde precisión rala, lo que permite a INLA utilizar métodos numéricos para\nmatrices ralas, que son más eficientes.\n\nLa estimación de INLA requiere la construcción de una grilla espacial (mesh). \nLa grilla es una colección de elementos geométricos (trángulos) que divide el\nespacio dimensional que contiene los sitios con observaciones a partir de la \ncual se estima la dependencia espacial de la variable respuesta.\n\nLa estimación de las covarianzas de los efectos de sitio se hacen a través de \nfunciones de suavizado impuestas sobre la grilla espacial. La aproximación \nSPDE (*Stochastic Partial Differential Equation*), agiliza el cómputo ya que la\nsolución se presenta como una matriz de covarianza de Mátern. \n\n\n\n\n\n::: {.callout-note appearance=\"simple\"}\n\nINLA puede ser usado para estimar modelo jerárquicos para datos espaciales con\nvariable de respuesta normal, binaria, binomial, conteos, es decir, en el \ncontexto de Modelos Lineales Generalizados Mixtos\n\n:::\n\n# Ilustración  {background-color=\"#546e7a\"}\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nSe tiene una respuesta continua ESPI (Ecosystem Services Provisioning Index) \nobservada en el territorio de la Cuenca del Carcarañá. El territorio está \ndividido en 4676 unidades de área de 1400 Has. cada una. Se dispone además \nde la covariable “Porcentaje de Pasturas Naturales Manejadas” en cada unidad\nde área. \n\n:::: {.columns}\n::: {.column width=\"47%\"}\n\n![Mapa de ESPI observado](img/01_espiobs.jpg)\n\n:::\n\n::: {.column width=\"3%\"}\n:::\n\n::: {.column width=\"50%\"}\n\n::: {style=\"font-size: 0.7em\"}\n\n| Región | ESPI | %PasturaNaturalManejada |\n|--------|------|:-----------------------:|\n| 1      | 2.11 | 1.90                    |\n| 2      | 1.35 | 0.20                    |\n| 3      | 1.84 | 19.33                   |\n| 4      | 2.04 | 60.08                   |\n| ...    | ...  | ...                     |\n| 4676   | 2.13 | 62.57                   |\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- Min: 0.088\n- Media: 1.84\n- DE: 0.287 \n- Max: 3\n\n:::\n\n::: {.column width=\"50%\"}\n![](img/02_espiHist.png){fig-align=\"center\"}\n:::\n\n::::\n\n:::\n::::\n\n\n\n\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nVamos a modelar el ESPI en función del porcentaje de pasturas en cada región $i$\nutilizando una regresión lineal bayesiana con efectos aleatorios de sitio _iid_\n\n$$y_i \\sim N \\big(\\mu, \\tau_{\\varepsilon}^{-1} \\big)$$\n\n$$E \\left[ y_i \\right] = \\beta_0 + \\beta_1 \\times Porc.Pasturas_i + \\mu_i$$\n\n\n$$u_i \\sim i.i.d \\ N \\big(0, \\tau_{u}^{-1} \\big)$$\n\n\nEn la regresión bayesiana, los parámetros $\\beta_0$ y $\\beta_1$ tienen \ndistribuciones a priori y en el jerárquico bayesiano, los hiperparámetros \n$\\tau_{\\varepsilon}^{-1}$ y $\\tau_{\\mu}^{-1}$ también. \n\nPor defecto, `INLA` asigna distribuciones a priori **no informativas** $N(0, 10e^5)$\npara $\\beta_0$ y $\\beta_1$, y $Gamma(0, 10e^5)$ para $\\tau_{\\varepsilon}^{-1}$ y $\\tau_{u}^{-1}$\n\n\n::: {.callout-note appearance=\"simple\"}\n\nComo sólo se tiene un nivel de observaciones y la respuesta es gaussiana,\nagregar efectos iid solo equivale a redistribuir la varianza entre el efecto\naleatorio y el error de las observaciones.\n\n:::\n\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nCorremos el modelo en `INLA`:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nm1 <- inla(\n  formula = ESPI ~ porcentaje_pasturas + f(id_region, model = 'iid'),\n  family = 'gaussian',\n  data = data,\n  control.compute = list(dic = TRUE, waic = TRUE),\n)\n```\n:::\n\n\nAl efecto aleatorio iid lo incluimos en la fórmula con `f(id_region, model = 'iid')`. \n\nCon `control.compute` le pedimos a `INLA` que calcule los criterios de \ninformación DIC y WAIC (menores = mejores).\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nDistribuciones a posteriori de los coeficientes de regresión:\n\n![](img/03_distparam.png){fig-align=\"center\"}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](img/04_disInter.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n![](img/05_DistPast.png){fig-align=\"center\"}\n:::\n\n::::\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nDistribuciones a posteriori para los hiperparámetros (escala de precisión $\\tau$)\n\n![](img/06_disHiper.png)\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\nGráfico en la escala de la desviación estándar $\\sigma$\n\n$$\\sigma^2 = \\frac{1}{\\tau}$$\n\n:::\n\n::: {.column width=\"50%\"}\n![](img/06_distribGrafHiper.png){fig-align=\"center\"}\n:::\n\n::::\n\n## Modelo Lineal Mixto iid para látice estimado vía INLA\n\nGráficos con los predichos y las observaciones, calculando el predicho \npuntual como la moda de la distribución a posteriori de los predichos:\n\n\n::: {style=\"font-size: 0.7em; text-align: center\"}\n\nDIC: 88  |   WAIC: -43\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![Predichos puntuales](img/07_predichos.jpg)\n:::\n\n::: {.column width=\"50%\"}\n\n![Observaciones](img/08_observados.jpg)\n\n:::\n\n::::\n\n\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\nEn vez de utilizar efectos aleatorios normales e idéndticamente distribuídos, \npodríamos utilizar efectos aleatorios con estructura espacial explícita. \n\nUn ejemplo clásico apra datos areales son los efectos con estructura\n_Intrinsic Conditional Autoregressive_ o ICAR (Besag, 1974):\n\n$$u_i \\vert u_{-1} \\sim N \\Big( \\frac{1}{N_1} \\sum_{j=1}^{n} a_{ij} u_j, \\frac{1}{\\tau_u N_i} \\Big)$$\n\ndonde $a_{ij} \\ne 0$ si y solo si las áreas $i$ y $j$ son vecinas, $N_i$ es la\ncantidad de áreas vecinas del área $i$, $u_{-1}$ se asume $\\sum_{j=1}^{n} u_i = 0$\n\nHay distintas maneras de definir cuándo dos áreas son vecinas y qué peso tomará \n$a_{ij}$ cuando lo son. Por ejemplo, podríamos tomar que son vecinas cuando se \ntocan al menos en un punto, y que $a_{ij} = 1$ cuando son vecinas. \n\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\n\n\nVamos a modelar el ESPI en función del porcentaje de pasturas en cada región $i$\nutilizando una regresión lineal bayesiana con efectos aleatorios espaciales ICAR:\n\n\n$$y_i \\sim N \\big(\\mu, \\sigma_{\\varepsilon}^{-2} \\big)$$\n\n$$E \\left[ y_i \\right] = \\beta_0 + \\beta_1 \\times Porc.Pasturas_i + u_i$$\n\n$$u_i \\vert u_{-1} \\sim N \\Big( \\frac{1}{N_1} \\sum_{j=1}^{n} a_{ij} u_j, \\frac{1}{\\tau_u N_i} \\Big)$$\n\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\nDefinimos un grafo con los vecindarios de cada región:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nadj <- poly2nb(data)\nvecindario <- nb2mat(adj, style = \"W\", zero.policy = TRUE) \n```\n:::\n\n\nCorremos el modelo en `INLA`:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nm2 <- inla(\n  formula = ESPI ~ porcentaje_pasturas + f(id_region, model = 'icar',\n                                           graph = vecindario),\n  family = 'gaussian',\n  data = data,\n  control.compute = list(dic = TRUE, waic = TRUE),\n)\n```\n:::\n\n\n\nLe pasamos el grafo al modelo en `f(…, graph = vecindario)`.\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\n\nDistribuciones a posteriori de los coeficientes de regresión:\n\n![](img/09_DistrCoeficarTabla.png){fig-align=\"center\"}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](img/10_distribGrafHiper.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n![](img/11_distribGrafHiper.png){fig-align=\"center\"}\n:::\n\n::::\n\n\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\n\n\nDistribuciones a posteriori para los hiperparámetros (escala de precisión $\\tau$)\n\n![](img/12_DistrCoeficarTabla.png){fig-align=\"center\"}\n\n![](img/13_sdHiper.png){fig-align=\"center\"}\n\n::: {.callout-note appearance=\"simple\"}\n\nEl desvio estandar del efecto aleatorio podría tener mayor magnitud que el\ndesvío estándar del ESPI observado, que era 0.287.\n\n:::\n\n\n## Modelo Lineal Mixto ICAR para látice estimado vía INLA\n\n\nGráficos con los predichos y las observaciones, calculando el predicho \npuntual como la moda de la distribución a posteriori de los predichos:\n\n::: {style=\"font-size: 0.7em; text-align: center\"}\n\nDIC: -3783  |   WAIC: -3862\n\n:::\n\n:::: {.columns}\n\n::: {.column width=\"49%\"}\n\n![Predichos puntuales](img/14_predichosicar.jpg)\n:::\n\n::: {.column width=\"49%\"}\n\n![Observaciones](img/08_observados.jpg)\n\n:::\n\n::::\n\n\n\n## Comentarios\n\nEntre estos ajustes, el modelo ICAR proporcionó menores DIC y WAIC. Ademas, \nen los mapas de predichos se observa que el ICAR logra captar el detalle de \nlas regiones con ESPI bajo, algo que el iid no logró. \n\nEn un modelo con efecto aleatorio de sitio y efecto aleatorio residual \nseparables podrían usarse distintos modelos para los distintos efectos \naleatorios. Por ejemplo ICAR para el efecto sitio e i.i.d para el residual\n\n\n\n# Modelo Lineal Mixto para datos contínuos estimado vía REML e INLA  {background-color=\"#546e7a\"}\n\n# Modelo Lineal Mixto para datos de conteo estimado vía INLA  {background-color=\"#546e7a\"}\n\n\n## Ejemplo MJB datos de conteo\n\n$$Y_i \\sim Poisson(\\theta_i) \\ \\ \\ \\ i = 1, \\dots, n$$\n\n$$log(\\theta_i) = \\beta_0 + \\beta_1 \\times x_i + \\dots + u_i + \\nu_i$$\n\n$$u_i \\vert u_{-i} \\sim N \\Bigg( \\bar{u}_{\\delta_i}, \\frac{\\sigma_{u}^{2}}{\\eta_{\\delta_i}} \\Bigg) $$\n\n$$\\nu \\sim N(0,\\sigma_{\\nu}^2)$$\nTasa estandarizada de incidencia (SIR)\n$$SIR_i = \\frac{Y_i}{E_i}$$\n\n\n\n:::{.callout-note}\n\n## Riesgo Relativo (RR) con datos espaciales\n\nRelación entre la probabilidad de que ocurra el evento en el sitio y la probabilidad\nde que el mismo evento ocurra en otro sitio.\n\n:::\n\n\n\n# Ejemplos de aplicación {background-color=\"#546e7a\"}\n\n[Ejercicios 1](Ej01.html){preview-link=\"true\"}\n\n[Ejercicios 2](Ej02.html){preview-link=\"true\"}\n\n\n# Gracias!\n",
    "supporting": [
      "slides_files\\figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}